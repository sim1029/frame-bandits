{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.7.5-cp38-cp38-win_amd64.whl (7.5 MB)\n",
      "Collecting torch==1.8.0\n",
      "  Downloading torch-1.8.0-cp38-cp38-win_amd64.whl (190.5 MB)\n",
      "Collecting torchvision==0.9.0\n",
      "  Downloading torchvision-0.9.0-cp38-cp38-win_amd64.whl (852 kB)\n",
      "Collecting gluoncv\n",
      "  Using cached gluoncv-0.10.5.post0-py2.py3-none-any.whl (1.3 MB)\n",
      "Collecting decord\n",
      "  Using cached decord-0.6.0-py3-none-win_amd64.whl (24.7 MB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from torch==1.8.0) (4.10.0)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.24.4-cp38-cp38-win_amd64.whl (14.9 MB)\n",
      "Collecting pillow>=4.1.1\n",
      "  Downloading pillow-10.2.0-cp38-cp38-win_amd64.whl (2.6 MB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.1.1-cp38-cp38-win_amd64.whl (477 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.5-cp38-cp38-win_amd64.whl (56 kB)\n",
      "Collecting importlib-resources>=3.2.0\n",
      "  Downloading importlib_resources-6.1.2-py3-none-any.whl (34 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.49.0-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Collecting yacs\n",
      "  Using cached yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.9.0.80-cp37-abi3-win_amd64.whl (38.6 MB)\n",
      "Collecting pyyaml\n",
      "  Downloading PyYAML-6.0.1-cp38-cp38-win_amd64.whl (157 kB)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.10.1-cp38-cp38-win_amd64.whl (42.2 MB)\n",
      "Collecting autocfg\n",
      "  Using cached autocfg-0.0.8-py3-none-any.whl (13 kB)\n",
      "Collecting portalocker\n",
      "  Using cached portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp38-cp38-win_amd64.whl (10.8 MB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from portalocker->gluoncv) (306)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.3.2-cp38-cp38-win_amd64.whl (99 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from tqdm->gluoncv) (0.4.6)\n",
      "Installing collected packages: numpy, urllib3, tzdata, pyyaml, pytz, pyparsing, pillow, kiwisolver, importlib-resources, idna, fonttools, cycler, contourpy, charset-normalizer, certifi, yacs, tqdm, torch, scipy, requests, portalocker, pandas, opencv-python, matplotlib, autocfg, torchvision, gluoncv, decord\n",
      "Successfully installed autocfg-0.0.8 certifi-2024.2.2 charset-normalizer-3.3.2 contourpy-1.1.1 cycler-0.12.1 decord-0.6.0 fonttools-4.49.0 gluoncv-0.10.5.post0 idna-3.6 importlib-resources-6.1.2 kiwisolver-1.4.5 matplotlib-3.7.5 numpy-1.24.4 opencv-python-4.9.0.80 pandas-2.0.3 pillow-10.2.0 portalocker-2.8.2 pyparsing-3.1.1 pytz-2024.1 pyyaml-6.0.1 requests-2.31.0 scipy-1.10.1 torch-1.8.0 torchvision-0.9.0 tqdm-4.66.2 tzdata-2024.1 urllib3-2.2.1 yacs-0.1.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'c:\\Users\\Owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts fonttools.exe, pyftmerge.exe, pyftsubset.exe and ttx.exe are installed in 'c:\\Users\\Owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script normalizer.exe is installed in 'c:\\Users\\Owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tqdm.exe is installed in 'c:\\Users\\Owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts convert-caffe2-to-onnx.exe and convert-onnx-to-caffe2.exe are installed in 'c:\\Users\\Owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 21.1.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib torch==1.8.0 torchvision==0.9.0 gluoncv decord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (9.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.1.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Getting Started with Pre-trained I3D Models on Kinetcis400\n",
    "\n",
    "`Kinetics400 <https://deepmind.com/research/open-source/kinetics>`_  is an action recognition dataset\n",
    "of realistic action videos, collected from YouTube. With 306,245 short trimmed videos\n",
    "from 400 action categories, it is one of the largest and most widely used dataset in the research\n",
    "community for benchmarking state-of-the-art video action recognition models.\n",
    "\n",
    "`I3D <https://arxiv.org/abs/1705.07750>`_ (Inflated 3D Networks) is a widely adopted 3D video\n",
    "classification network. It uses 3D convolution to learn spatiotemporal information directly from videos.\n",
    "I3D is proposed to improve `C3D <https://arxiv.org/abs/1412.0767>`_ (Convolutional 3D Networks) by inflating from 2D models.\n",
    "We can not only reuse the 2D models' architecture (e.g., ResNet, Inception), but also bootstrap\n",
    "the model weights from 2D pretrained models. In this manner, training 3D networks for video\n",
    "classification is feasible and getting much better results.\n",
    "\n",
    "In this tutorial, we will demonstrate how to load a pre-trained I3D model from `gluoncv-model-zoo`\n",
    "and classify a video clip from the Internet or your local disk into one of the 400 action classes.\n",
    "\n",
    "## Step by Step\n",
    "\n",
    "We will try out a pre-trained I3D model on a single video clip.\n",
    "\n",
    "First, please follow the `installation guide <../../index.html#installation>`__\n",
    "to install ``PyTorch`` and ``GluonCV`` if you haven't done so yet.\n",
    "\n",
    "## Simon's Fixes to Installation Instructions\n",
    "\n",
    "1. Use python 3.8\n",
    "2. Run `pip install torch==1.6.0 torchvision==0.7.0 gluoncv decord`\n",
    "3. Run `pip uninstall Pillow`\n",
    "4. Run `pip install Pillow==9.5.0`\n",
    "5. (Optional) install Jupyter lab to run example notebook linked in tutorial `pip install jupyterlab`\n",
    "6. Download the model config to download the pretrained model used in the tutorial (you will need to edit the config file path to where this file is stored on your system when running the code block which loads the model): https://raw.githubusercontent.com/dmlc/gluon-cv/master/scripts/action-recognition/configuration/resnet50_v1b_kinetics400.yaml\n",
    "7. Run the notebook and check if class 0 (abseiling) is the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import decord\n",
    "import torch\n",
    "\n",
    "from gluoncv.torch.utils.model_utils import download\n",
    "from gluoncv.torch.data.transforms.videotransforms import video_transforms, volume_transforms\n",
    "from gluoncv.torch.engine.config import get_cfg_defaults\n",
    "from gluoncv.torch.model_zoo import get_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we download a video and extract a 32-frame clip from it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://github.com/bryanyzhu/tiny-ucf101/raw/master/abseiling_k400.mp4'  # contains 250 frames\n",
    "video_fname = download(url)\n",
    "vr = decord.VideoReader(video_fname)\n",
    "frame_id_list = [5, 6, 7, 8, 9]\n",
    "video_data = vr.get_batch(frame_id_list).asnumpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define transformations for the video clip.\n",
    "This transformation function does four things:\n",
    "(1) resize the shorter side of video clip to short_side_size,\n",
    "(2) center crop the video clip to crop_size x crop_size,\n",
    "(3) transpose the video clip to ``num_channels*num_frames*height*width``,\n",
    "and (4) normalize it with mean and standard deviation calculated across all ImageNet images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video data is downloaded and preprocessed.\n"
     ]
    }
   ],
   "source": [
    "crop_size = 224\n",
    "short_side_size = 256\n",
    "transform_fn = video_transforms.Compose([video_transforms.Resize(short_side_size, interpolation='bilinear'),\n",
    "                                         video_transforms.CenterCrop(size=(crop_size, crop_size)),\n",
    "                                         volume_transforms.ClipToTensor(),\n",
    "                                         video_transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "clip_input = transform_fn(video_data)\n",
    "print('Video data is downloaded and preprocessed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load a pre-trained I3D model. Make sure to change the ``pretrained`` in the configuration file to True.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i3d_resnet50_v1_kinetics400 model is successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "config_file = './i3d_resnet50_v1_kinetics400.yaml'\n",
    "cfg = get_cfg_defaults()\n",
    "cfg.merge_from_file(config_file)\n",
    "model = get_model(cfg)\n",
    "model.eval()\n",
    "print('%s model is successfully loaded.' % cfg.CONFIG.MODEL.NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we prepare the video clip and feed it to the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input video clip is classified as class 0 with confidence interval 0.7715625166893005\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    pred = model(torch.unsqueeze(clip_input, dim=0)).numpy()\n",
    "\n",
    "# Convert raw logits to probabilities using softmax\n",
    "probs = torch.nn.functional.softmax(torch.tensor(pred), dim=1).numpy()\n",
    "\n",
    "# Get the top predicted class and calculate confidence interval\n",
    "top_class = np.argmax(probs)\n",
    "confidence_interval = np.max(probs) - np.min(probs)\n",
    "\n",
    "print(f'The input video clip is classified as class {top_class} with confidence interval {confidence_interval}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input video clip is classified as class 0 with confidence interval 0.9443979263305664 for frame window 4\n",
      "The input video clip is classified as class 0 with confidence interval 0.9288216233253479 for frame window 6\n",
      "The input video clip is classified as class 0 with confidence interval 0.9487528204917908 for frame window 8\n",
      "The input video clip is classified as class 0 with confidence interval 0.8573697805404663 for frame window 10\n",
      "The input video clip is classified as class 0 with confidence interval 0.8656697273254395 for frame window 12\n",
      "The input video clip is classified as class 0 with confidence interval 0.9996094107627869 for frame window 14\n",
      "The input video clip is classified as class 0 with confidence interval 0.9967054724693298 for frame window 16\n",
      "The input video clip is classified as class 0 with confidence interval 0.9980602860450745 for frame window 18\n",
      "The input video clip is classified as class 0 with confidence interval 0.9998185038566589 for frame window 20\n",
      "The input video clip is classified as class 0 with confidence interval 0.9997139573097229 for frame window 22\n",
      "The input video clip is classified as class 0 with confidence interval 0.9975398778915405 for frame window 24\n",
      "The input video clip is classified as class 0 with confidence interval 0.9937281608581543 for frame window 26\n",
      "The input video clip is classified as class 0 with confidence interval 0.9825072884559631 for frame window 28\n",
      "The input video clip is classified as class 0 with confidence interval 0.9368579387664795 for frame window 30\n",
      "The input video clip is classified as class 0 with confidence interval 0.9946658611297607 for frame window 32\n",
      "The input video clip is classified as class 0 with confidence interval 0.9998142123222351 for frame window 34\n",
      "The input video clip is classified as class 0 with confidence interval 0.8996824622154236 for frame window 36\n",
      "The input video clip is classified as class 0 with confidence interval 0.689360499382019 for frame window 38\n",
      "The input video clip is classified as class 0 with confidence interval 0.9966878294944763 for frame window 40\n",
      "The input video clip is classified as class 0 with confidence interval 0.8617103695869446 for frame window 42\n",
      "The input video clip is classified as class 0 with confidence interval 0.9668689370155334 for frame window 44\n",
      "The input video clip is classified as class 0 with confidence interval 0.9475434422492981 for frame window 46\n",
      "The input video clip is classified as class 0 with confidence interval 0.9914173483848572 for frame window 48\n",
      "The input video clip is classified as class 0 with confidence interval 0.920516312122345 for frame window 50\n",
      "The input video clip is classified as class 0 with confidence interval 0.9255295395851135 for frame window 52\n",
      "The input video clip is classified as class 0 with confidence interval 0.9954297542572021 for frame window 54\n",
      "The input video clip is classified as class 0 with confidence interval 0.9992875456809998 for frame window 56\n",
      "The input video clip is classified as class 0 with confidence interval 0.995429515838623 for frame window 58\n",
      "The input video clip is classified as class 0 with confidence interval 0.9150633215904236 for frame window 60\n",
      "The input video clip is classified as class 0 with confidence interval 0.6436271071434021 for frame window 62\n",
      "The input video clip is classified as class 0 with confidence interval 0.9706125259399414 for frame window 64\n",
      "The input video clip is classified as class 0 with confidence interval 0.5375920534133911 for frame window 66\n",
      "The input video clip is classified as class 0 with confidence interval 0.999358594417572 for frame window 68\n",
      "The input video clip is classified as class 0 with confidence interval 0.9972917437553406 for frame window 70\n",
      "The input video clip is classified as class 0 with confidence interval 0.9998817443847656 for frame window 72\n",
      "The input video clip is classified as class 0 with confidence interval 0.9569452404975891 for frame window 74\n",
      "The input video clip is classified as class 0 with confidence interval 0.8689625263214111 for frame window 76\n",
      "The input video clip is classified as class 0 with confidence interval 0.9860199093818665 for frame window 78\n",
      "The input video clip is classified as class 0 with confidence interval 0.750203013420105 for frame window 80\n",
      "The input video clip is classified as class 0 with confidence interval 0.9827246069908142 for frame window 82\n",
      "The input video clip is classified as class 0 with confidence interval 0.9976939558982849 for frame window 84\n",
      "The input video clip is classified as class 0 with confidence interval 0.9994931221008301 for frame window 86\n",
      "The input video clip is classified as class 0 with confidence interval 0.9995567202568054 for frame window 88\n",
      "The input video clip is classified as class 0 with confidence interval 0.9974586367607117 for frame window 90\n",
      "The input video clip is classified as class 0 with confidence interval 0.9889679551124573 for frame window 92\n",
      "The input video clip is classified as class 0 with confidence interval 0.9529868960380554 for frame window 94\n",
      "The input video clip is classified as class 0 with confidence interval 0.9977680444717407 for frame window 96\n",
      "The input video clip is classified as class 0 with confidence interval 0.9931414723396301 for frame window 98\n",
      "The input video clip is classified as class 0 with confidence interval 0.9977370500564575 for frame window 100\n",
      "The input video clip is classified as class 0 with confidence interval 0.9926111102104187 for frame window 102\n",
      "The input video clip is classified as class 0 with confidence interval 0.9940253496170044 for frame window 104\n",
      "The input video clip is classified as class 0 with confidence interval 0.9985648989677429 for frame window 106\n",
      "The input video clip is classified as class 0 with confidence interval 0.9904617667198181 for frame window 108\n",
      "The input video clip is classified as class 0 with confidence interval 0.9982805252075195 for frame window 110\n",
      "The input video clip is classified as class 0 with confidence interval 0.9990044236183167 for frame window 112\n",
      "The input video clip is classified as class 0 with confidence interval 0.9992477893829346 for frame window 114\n",
      "The input video clip is classified as class 0 with confidence interval 0.9988102912902832 for frame window 116\n",
      "The input video clip is classified as class 0 with confidence interval 0.9992699027061462 for frame window 118\n",
      "The input video clip is classified as class 0 with confidence interval 0.9972791075706482 for frame window 120\n",
      "The input video clip is classified as class 0 with confidence interval 0.9910793900489807 for frame window 122\n",
      "The input video clip is classified as class 0 with confidence interval 0.9797502756118774 for frame window 124\n",
      "The input video clip is classified as class 0 with confidence interval 0.9918460249900818 for frame window 126\n",
      "The input video clip is classified as class 0 with confidence interval 0.9944716691970825 for frame window 128\n",
      "The input video clip is classified as class 0 with confidence interval 0.987395167350769 for frame window 130\n",
      "The input video clip is classified as class 0 with confidence interval 0.9977136850357056 for frame window 132\n",
      "The input video clip is classified as class 0 with confidence interval 0.9987995624542236 for frame window 134\n",
      "The input video clip is classified as class 0 with confidence interval 0.9975002408027649 for frame window 136\n",
      "The input video clip is classified as class 0 with confidence interval 0.9995040893554688 for frame window 138\n",
      "The input video clip is classified as class 0 with confidence interval 0.9297031164169312 for frame window 140\n",
      "The input video clip is classified as class 0 with confidence interval 0.9769559502601624 for frame window 142\n",
      "The input video clip is classified as class 0 with confidence interval 0.9853157997131348 for frame window 144\n",
      "The input video clip is classified as class 0 with confidence interval 0.9804937243461609 for frame window 146\n",
      "The input video clip is classified as class 0 with confidence interval 0.9638527631759644 for frame window 148\n",
      "The input video clip is classified as class 0 with confidence interval 0.9757973551750183 for frame window 150\n",
      "The input video clip is classified as class 0 with confidence interval 0.9930111765861511 for frame window 152\n",
      "The input video clip is classified as class 0 with confidence interval 0.997333288192749 for frame window 154\n",
      "The input video clip is classified as class 0 with confidence interval 0.9990183115005493 for frame window 156\n",
      "The input video clip is classified as class 0 with confidence interval 0.9990934133529663 for frame window 158\n",
      "The input video clip is classified as class 0 with confidence interval 0.9929639101028442 for frame window 160\n",
      "The input video clip is classified as class 0 with confidence interval 0.9958603978157043 for frame window 162\n",
      "The input video clip is classified as class 0 with confidence interval 0.996155321598053 for frame window 164\n",
      "The input video clip is classified as class 0 with confidence interval 0.996828019618988 for frame window 166\n",
      "The input video clip is classified as class 0 with confidence interval 0.9979215264320374 for frame window 168\n",
      "The input video clip is classified as class 0 with confidence interval 0.999167799949646 for frame window 170\n",
      "The input video clip is classified as class 0 with confidence interval 0.9551319479942322 for frame window 172\n",
      "The input video clip is classified as class 0 with confidence interval 0.7819214463233948 for frame window 174\n",
      "The input video clip is classified as class 0 with confidence interval 0.9520872235298157 for frame window 176\n",
      "The input video clip is classified as class 0 with confidence interval 0.9053062796592712 for frame window 178\n",
      "The input video clip is classified as class 0 with confidence interval 0.8995866775512695 for frame window 180\n",
      "The input video clip is classified as class 0 with confidence interval 0.861530601978302 for frame window 182\n",
      "The input video clip is classified as class 0 with confidence interval 0.7619664072990417 for frame window 184\n",
      "The input video clip is classified as class 0 with confidence interval 0.9524771571159363 for frame window 186\n",
      "The input video clip is classified as class 0 with confidence interval 0.9864971041679382 for frame window 188\n",
      "The input video clip is classified as class 0 with confidence interval 0.9722564220428467 for frame window 190\n",
      "The input video clip is classified as class 0 with confidence interval 0.9915008544921875 for frame window 192\n",
      "The input video clip is classified as class 0 with confidence interval 0.9865692853927612 for frame window 194\n",
      "The input video clip is classified as class 0 with confidence interval 0.9862114191055298 for frame window 196\n",
      "The input video clip is classified as class 0 with confidence interval 0.9756143093109131 for frame window 198\n",
      "The input video clip is classified as class 0 with confidence interval 0.9697496294975281 for frame window 200\n",
      "The input video clip is classified as class 0 with confidence interval 0.8946422934532166 for frame window 202\n",
      "The input video clip is classified as class 0 with confidence interval 0.99184250831604 for frame window 204\n",
      "The input video clip is classified as class 0 with confidence interval 0.9596207141876221 for frame window 206\n",
      "The input video clip is classified as class 0 with confidence interval 0.9271615147590637 for frame window 208\n",
      "The input video clip is classified as class 0 with confidence interval 0.9766150712966919 for frame window 210\n",
      "The input video clip is classified as class 0 with confidence interval 0.8940353989601135 for frame window 212\n",
      "The input video clip is classified as class 0 with confidence interval 0.9401156902313232 for frame window 214\n",
      "The input video clip is classified as class 0 with confidence interval 0.9363002777099609 for frame window 216\n",
      "The input video clip is classified as class 49 with confidence interval 0.5195550918579102 for frame window 218\n",
      "The input video clip is classified as class 49 with confidence interval 0.6526317596435547 for frame window 220\n",
      "The input video clip is classified as class 49 with confidence interval 0.6348962187767029 for frame window 222\n",
      "The input video clip is classified as class 49 with confidence interval 0.729002058506012 for frame window 224\n",
      "The input video clip is classified as class 49 with confidence interval 0.9670622944831848 for frame window 226\n",
      "The input video clip is classified as class 0 with confidence interval 0.6014057993888855 for frame window 228\n",
      "The input video clip is classified as class 49 with confidence interval 0.7575487494468689 for frame window 230\n",
      "The input video clip is classified as class 0 with confidence interval 0.5689826011657715 for frame window 232\n",
      "The input video clip is classified as class 0 with confidence interval 0.9466061592102051 for frame window 234\n",
      "The input video clip is classified as class 0 with confidence interval 0.9515309929847717 for frame window 236\n",
      "The input video clip is classified as class 0 with confidence interval 0.8410243391990662 for frame window 238\n",
      "The input video clip is classified as class 0 with confidence interval 0.9669464826583862 for frame window 240\n",
      "The input video clip is classified as class 0 with confidence interval 0.9506780505180359 for frame window 242\n",
      "The input video clip is classified as class 0 with confidence interval 0.9491497278213501 for frame window 244\n"
     ]
    }
   ],
   "source": [
    "url = 'https://github.com/bryanyzhu/tiny-ucf101/raw/master/abseiling_k400.mp4' \n",
    "video_fname = download(url)\n",
    "vr = decord.VideoReader(video_fname)\n",
    "config_file = './i3d_resnet50_v1_kinetics400.yaml'\n",
    "cfg = get_cfg_defaults()\n",
    "cfg.merge_from_file(config_file)\n",
    "model = get_model(cfg)\n",
    "model.eval()\n",
    "for i in range(4, len(vr) - 4, 2):\n",
    "    frame_id_list = range(i - 4, i + 5, 2)\n",
    "    video_data = vr.get_batch(frame_id_list).asnumpy()\n",
    "    crop_size = 224\n",
    "    short_side_size = 256\n",
    "    transform_fn = video_transforms.Compose([video_transforms.Resize(short_side_size, interpolation='bilinear'),\n",
    "                                            video_transforms.CenterCrop(size=(crop_size, crop_size)),\n",
    "                                            volume_transforms.ClipToTensor(),\n",
    "                                            video_transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "    clip_input = transform_fn(video_data)\n",
    "    with torch.no_grad():\n",
    "        pred = model(torch.unsqueeze(clip_input, dim=0)).numpy()\n",
    "\n",
    "    # Convert raw logits to probabilities using softmax\n",
    "    probs = torch.nn.functional.softmax(torch.tensor(pred), dim=1).numpy()\n",
    "\n",
    "    # Get the top predicted class and calculate confidence interval\n",
    "    top_class = np.argmax(probs)\n",
    "    confidence_interval = np.max(probs) - np.min(probs)\n",
    "\n",
    "    print(f'The input video clip is classified as class {top_class} with confidence interval {confidence_interval} for frame window {i}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our pre-trained model predicts this video clip\n",
    "to be ``abseiling`` action with high confidence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step\n",
    "\n",
    "If you would like to dive deeper into finetuing SOTA video models on your datasets,\n",
    "feel free to read the next `tutorial on finetuning <finetune_custom.html>`__.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
