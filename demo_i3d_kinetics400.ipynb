{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional pip installation (for Winddows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.7.5-cp38-cp38-win_amd64.whl (7.5 MB)\n",
      "Collecting torch==1.8.0\n",
      "  Downloading torch-1.8.0-cp38-cp38-win_amd64.whl (190.5 MB)\n",
      "Collecting torchvision==0.9.0\n",
      "  Downloading torchvision-0.9.0-cp38-cp38-win_amd64.whl (852 kB)\n",
      "Collecting gluoncv\n",
      "  Using cached gluoncv-0.10.5.post0-py2.py3-none-any.whl (1.3 MB)\n",
      "Collecting decord\n",
      "  Using cached decord-0.6.0-py3-none-win_amd64.whl (24.7 MB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from torch==1.8.0) (4.10.0)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.24.4-cp38-cp38-win_amd64.whl (14.9 MB)\n",
      "Collecting pillow>=4.1.1\n",
      "  Downloading pillow-10.2.0-cp38-cp38-win_amd64.whl (2.6 MB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.1.1-cp38-cp38-win_amd64.whl (477 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.5-cp38-cp38-win_amd64.whl (56 kB)\n",
      "Collecting importlib-resources>=3.2.0\n",
      "  Downloading importlib_resources-6.1.2-py3-none-any.whl (34 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.49.0-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Collecting yacs\n",
      "  Using cached yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.9.0.80-cp37-abi3-win_amd64.whl (38.6 MB)\n",
      "Collecting pyyaml\n",
      "  Downloading PyYAML-6.0.1-cp38-cp38-win_amd64.whl (157 kB)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.10.1-cp38-cp38-win_amd64.whl (42.2 MB)\n",
      "Collecting autocfg\n",
      "  Using cached autocfg-0.0.8-py3-none-any.whl (13 kB)\n",
      "Collecting portalocker\n",
      "  Using cached portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp38-cp38-win_amd64.whl (10.8 MB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from portalocker->gluoncv) (306)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.3.2-cp38-cp38-win_amd64.whl (99 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from tqdm->gluoncv) (0.4.6)\n",
      "Installing collected packages: numpy, urllib3, tzdata, pyyaml, pytz, pyparsing, pillow, kiwisolver, importlib-resources, idna, fonttools, cycler, contourpy, charset-normalizer, certifi, yacs, tqdm, torch, scipy, requests, portalocker, pandas, opencv-python, matplotlib, autocfg, torchvision, gluoncv, decord\n",
      "Successfully installed autocfg-0.0.8 certifi-2024.2.2 charset-normalizer-3.3.2 contourpy-1.1.1 cycler-0.12.1 decord-0.6.0 fonttools-4.49.0 gluoncv-0.10.5.post0 idna-3.6 importlib-resources-6.1.2 kiwisolver-1.4.5 matplotlib-3.7.5 numpy-1.24.4 opencv-python-4.9.0.80 pandas-2.0.3 pillow-10.2.0 portalocker-2.8.2 pyparsing-3.1.1 pytz-2024.1 pyyaml-6.0.1 requests-2.31.0 scipy-1.10.1 torch-1.8.0 torchvision-0.9.0 tqdm-4.66.2 tzdata-2024.1 urllib3-2.2.1 yacs-0.1.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'c:\\Users\\Owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts fonttools.exe, pyftmerge.exe, pyftsubset.exe and ttx.exe are installed in 'c:\\Users\\Owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script normalizer.exe is installed in 'c:\\Users\\Owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tqdm.exe is installed in 'c:\\Users\\Owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts convert-caffe2-to-onnx.exe and convert-onnx-to-caffe2.exe are installed in 'c:\\Users\\Owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 21.1.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib torch==1.8.0 torchvision==0.9.0 gluoncv decord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (9.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.1.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Getting Started with Pre-trained I3D Models on Kinetcis400\n",
    "\n",
    "`Kinetics400 <https://deepmind.com/research/open-source/kinetics>`_  is an action recognition dataset\n",
    "of realistic action videos, collected from YouTube. With 306,245 short trimmed videos\n",
    "from 400 action categories, it is one of the largest and most widely used dataset in the research\n",
    "community for benchmarking state-of-the-art video action recognition models.\n",
    "\n",
    "`I3D <https://arxiv.org/abs/1705.07750>`_ (Inflated 3D Networks) is a widely adopted 3D video\n",
    "classification network. It uses 3D convolution to learn spatiotemporal information directly from videos.\n",
    "I3D is proposed to improve `C3D <https://arxiv.org/abs/1412.0767>`_ (Convolutional 3D Networks) by inflating from 2D models.\n",
    "We can not only reuse the 2D models' architecture (e.g., ResNet, Inception), but also bootstrap\n",
    "the model weights from 2D pretrained models. In this manner, training 3D networks for video\n",
    "classification is feasible and getting much better results.\n",
    "\n",
    "In this tutorial, we will demonstrate how to load a pre-trained I3D model from `gluoncv-model-zoo`\n",
    "and classify a video clip from the Internet or your local disk into one of the 400 action classes.\n",
    "\n",
    "## Step by Step\n",
    "\n",
    "We will try out a pre-trained I3D model on a single video clip.\n",
    "\n",
    "First, please follow the `installation guide <../../index.html#installation>`__\n",
    "to install ``PyTorch`` and ``GluonCV`` if you haven't done so yet.\n",
    "\n",
    "## Simon's Fixes to Installation Instructions\n",
    "\n",
    "1. Use python 3.8\n",
    "2. Run `pip install torch==1.6.0 torchvision==0.7.0 gluoncv decord`\n",
    "3. Run `pip uninstall Pillow`\n",
    "4. Run `pip install Pillow==9.5.0`\n",
    "5. (Optional) install Jupyter lab to run example notebook linked in tutorial `pip install jupyterlab`\n",
    "6. Download the model config to download the pretrained model used in the tutorial (you will need to edit the config file path to where this file is stored on your system when running the code block which loads the model): https://raw.githubusercontent.com/dmlc/gluon-cv/master/scripts/action-recognition/configuration/resnet50_v1b_kinetics400.yaml\n",
    "7. Run the notebook and check if class 0 (abseiling) is the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import decord\n",
    "import torch\n",
    "\n",
    "from gluoncv.torch.utils.model_utils import download\n",
    "from gluoncv.torch.data.transforms.videotransforms import video_transforms, volume_transforms\n",
    "from gluoncv.torch.engine.config import get_cfg_defaults\n",
    "from gluoncv.torch.model_zoo import get_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we download a video and extract a 32-frame clip from it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://github.com/bryanyzhu/tiny-ucf101/raw/master/abseiling_k400.mp4'  # contains 250 frames\n",
    "video_fname = download(url)\n",
    "vr = decord.VideoReader(video_fname)\n",
    "frame_id_list = [5, 6, 7, 8, 9]\n",
    "video_data = vr.get_batch(frame_id_list).asnumpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define transformations for the video clip.\n",
    "This transformation function does four things:\n",
    "(1) resize the shorter side of video clip to short_side_size,\n",
    "(2) center crop the video clip to crop_size x crop_size,\n",
    "(3) transpose the video clip to ``num_channels*num_frames*height*width``,\n",
    "and (4) normalize it with mean and standard deviation calculated across all ImageNet images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video data is downloaded and preprocessed.\n"
     ]
    }
   ],
   "source": [
    "crop_size = 224\n",
    "short_side_size = 256\n",
    "transform_fn = video_transforms.Compose([video_transforms.Resize(short_side_size, interpolation='bilinear'),\n",
    "                                         video_transforms.CenterCrop(size=(crop_size, crop_size)),\n",
    "                                         volume_transforms.ClipToTensor(),\n",
    "                                         video_transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "clip_input = transform_fn(video_data)\n",
    "print('Video data is downloaded and preprocessed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load a pre-trained I3D model. Make sure to change the ``pretrained`` in the configuration file to True.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i3d_resnet50_v1_kinetics400 model is successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "config_file = './i3d_resnet50_v1_kinetics400.yaml'\n",
    "cfg = get_cfg_defaults()\n",
    "cfg.merge_from_file(config_file)\n",
    "model = get_model(cfg)\n",
    "model.eval()\n",
    "print('%s model is successfully loaded.' % cfg.CONFIG.MODEL.NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we prepare the video clip and feed it to the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input video clip is classified as class 0 with confidence interval 0.7715625166893005\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    pred = model(torch.unsqueeze(clip_input, dim=0)).numpy()\n",
    "\n",
    "# Convert raw logits to probabilities using softmax\n",
    "probs = torch.nn.functional.softmax(torch.tensor(pred), dim=1).numpy()\n",
    "\n",
    "# Get the top predicted class and calculate confidence interval\n",
    "top_class = np.argmax(probs)\n",
    "confidence_interval = np.max(probs) - np.min(probs)\n",
    "\n",
    "print(f'The input video clip is classified as class {top_class} with confidence interval {confidence_interval}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate confidence of frame windows\n",
    "##### Adjust the 'N' value to set the step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input video clip is classified as class 0 with confidence interval 0.9928627610206604 for frame window 8\n",
      "The input video clip is classified as class 0 with confidence interval 0.963922381401062 for frame window 10\n",
      "The input video clip is classified as class 0 with confidence interval 0.8847163319587708 for frame window 12\n",
      "The input video clip is classified as class 0 with confidence interval 0.9969870448112488 for frame window 14\n",
      "The input video clip is classified as class 0 with confidence interval 0.9855148792266846 for frame window 16\n",
      "The input video clip is classified as class 0 with confidence interval 0.9987284541130066 for frame window 18\n",
      "The input video clip is classified as class 0 with confidence interval 0.9997177720069885 for frame window 20\n",
      "The input video clip is classified as class 0 with confidence interval 0.9983910322189331 for frame window 22\n",
      "The input video clip is classified as class 0 with confidence interval 0.99607914686203 for frame window 24\n",
      "The input video clip is classified as class 0 with confidence interval 0.9929880499839783 for frame window 26\n",
      "The input video clip is classified as class 0 with confidence interval 0.923012912273407 for frame window 28\n",
      "The input video clip is classified as class 0 with confidence interval 0.9753429889678955 for frame window 30\n",
      "The input video clip is classified as class 0 with confidence interval 0.9948776960372925 for frame window 32\n",
      "The input video clip is classified as class 0 with confidence interval 0.9973134398460388 for frame window 34\n",
      "The input video clip is classified as class 0 with confidence interval 0.9707596898078918 for frame window 36\n",
      "The input video clip is classified as class 0 with confidence interval 0.9268758296966553 for frame window 38\n",
      "The input video clip is classified as class 0 with confidence interval 0.9901740550994873 for frame window 40\n",
      "The input video clip is classified as class 0 with confidence interval 0.9535295963287354 for frame window 42\n",
      "The input video clip is classified as class 0 with confidence interval 0.9915124773979187 for frame window 44\n",
      "The input video clip is classified as class 0 with confidence interval 0.9657297730445862 for frame window 46\n",
      "The input video clip is classified as class 0 with confidence interval 0.9958882927894592 for frame window 48\n",
      "The input video clip is classified as class 0 with confidence interval 0.9738491177558899 for frame window 50\n",
      "The input video clip is classified as class 0 with confidence interval 0.9786669015884399 for frame window 52\n",
      "The input video clip is classified as class 0 with confidence interval 0.998621940612793 for frame window 54\n",
      "The input video clip is classified as class 0 with confidence interval 0.999369204044342 for frame window 56\n",
      "The input video clip is classified as class 0 with confidence interval 0.9899622201919556 for frame window 58\n",
      "The input video clip is classified as class 0 with confidence interval 0.9422221183776855 for frame window 60\n",
      "The input video clip is classified as class 0 with confidence interval 0.6817384362220764 for frame window 62\n",
      "The input video clip is classified as class 0 with confidence interval 0.9964303374290466 for frame window 64\n",
      "The input video clip is classified as class 0 with confidence interval 0.9250084161758423 for frame window 66\n",
      "The input video clip is classified as class 0 with confidence interval 0.9997542500495911 for frame window 68\n",
      "The input video clip is classified as class 0 with confidence interval 0.9995942711830139 for frame window 70\n",
      "The input video clip is classified as class 0 with confidence interval 0.999677300453186 for frame window 72\n",
      "The input video clip is classified as class 0 with confidence interval 0.9589601159095764 for frame window 74\n",
      "The input video clip is classified as class 0 with confidence interval 0.9680113196372986 for frame window 76\n",
      "The input video clip is classified as class 0 with confidence interval 0.9942262768745422 for frame window 78\n",
      "The input video clip is classified as class 0 with confidence interval 0.9210168123245239 for frame window 80\n",
      "The input video clip is classified as class 0 with confidence interval 0.9855615496635437 for frame window 82\n",
      "The input video clip is classified as class 0 with confidence interval 0.997772753238678 for frame window 84\n",
      "The input video clip is classified as class 0 with confidence interval 0.9998098015785217 for frame window 86\n",
      "The input video clip is classified as class 0 with confidence interval 0.9997677206993103 for frame window 88\n",
      "The input video clip is classified as class 0 with confidence interval 0.9895949363708496 for frame window 90\n",
      "The input video clip is classified as class 0 with confidence interval 0.9644880890846252 for frame window 92\n",
      "The input video clip is classified as class 0 with confidence interval 0.9631485939025879 for frame window 94\n",
      "The input video clip is classified as class 0 with confidence interval 0.9977948665618896 for frame window 96\n",
      "The input video clip is classified as class 0 with confidence interval 0.9950435161590576 for frame window 98\n",
      "The input video clip is classified as class 0 with confidence interval 0.9990593791007996 for frame window 100\n",
      "The input video clip is classified as class 0 with confidence interval 0.9970568418502808 for frame window 102\n",
      "The input video clip is classified as class 0 with confidence interval 0.9976416826248169 for frame window 104\n",
      "The input video clip is classified as class 0 with confidence interval 0.999480664730072 for frame window 106\n",
      "The input video clip is classified as class 0 with confidence interval 0.9947721362113953 for frame window 108\n",
      "The input video clip is classified as class 0 with confidence interval 0.9977012276649475 for frame window 110\n",
      "The input video clip is classified as class 0 with confidence interval 0.9984180927276611 for frame window 112\n",
      "The input video clip is classified as class 0 with confidence interval 0.9991044402122498 for frame window 114\n",
      "The input video clip is classified as class 0 with confidence interval 0.9984129667282104 for frame window 116\n",
      "The input video clip is classified as class 0 with confidence interval 0.9985509514808655 for frame window 118\n",
      "The input video clip is classified as class 0 with confidence interval 0.9958831071853638 for frame window 120\n",
      "The input video clip is classified as class 0 with confidence interval 0.993938684463501 for frame window 122\n",
      "The input video clip is classified as class 0 with confidence interval 0.9910067915916443 for frame window 124\n",
      "The input video clip is classified as class 0 with confidence interval 0.9968605041503906 for frame window 126\n",
      "The input video clip is classified as class 0 with confidence interval 0.9897428154945374 for frame window 128\n",
      "The input video clip is classified as class 0 with confidence interval 0.9893078207969666 for frame window 130\n",
      "The input video clip is classified as class 0 with confidence interval 0.9905691146850586 for frame window 132\n",
      "The input video clip is classified as class 0 with confidence interval 0.9984139204025269 for frame window 134\n",
      "The input video clip is classified as class 0 with confidence interval 0.978147566318512 for frame window 136\n",
      "The input video clip is classified as class 0 with confidence interval 0.9985419511795044 for frame window 138\n",
      "The input video clip is classified as class 0 with confidence interval 0.9747394919395447 for frame window 140\n",
      "The input video clip is classified as class 0 with confidence interval 0.9733890891075134 for frame window 142\n",
      "The input video clip is classified as class 0 with confidence interval 0.9805787205696106 for frame window 144\n",
      "The input video clip is classified as class 0 with confidence interval 0.8702898621559143 for frame window 146\n",
      "The input video clip is classified as class 0 with confidence interval 0.8842286467552185 for frame window 148\n",
      "The input video clip is classified as class 0 with confidence interval 0.9784294366836548 for frame window 150\n",
      "The input video clip is classified as class 0 with confidence interval 0.9870211482048035 for frame window 152\n",
      "The input video clip is classified as class 0 with confidence interval 0.9945801496505737 for frame window 154\n",
      "The input video clip is classified as class 0 with confidence interval 0.9978256821632385 for frame window 156\n",
      "The input video clip is classified as class 0 with confidence interval 0.999214768409729 for frame window 158\n",
      "The input video clip is classified as class 0 with confidence interval 0.9964722394943237 for frame window 160\n",
      "The input video clip is classified as class 0 with confidence interval 0.9978572726249695 for frame window 162\n",
      "The input video clip is classified as class 0 with confidence interval 0.9967380166053772 for frame window 164\n",
      "The input video clip is classified as class 0 with confidence interval 0.9948977828025818 for frame window 166\n",
      "The input video clip is classified as class 0 with confidence interval 0.9973863959312439 for frame window 168\n",
      "The input video clip is classified as class 0 with confidence interval 0.9869779944419861 for frame window 170\n",
      "The input video clip is classified as class 0 with confidence interval 0.9450021982192993 for frame window 172\n",
      "The input video clip is classified as class 0 with confidence interval 0.7800308465957642 for frame window 174\n",
      "The input video clip is classified as class 0 with confidence interval 0.9830896854400635 for frame window 176\n",
      "The input video clip is classified as class 0 with confidence interval 0.9101486206054688 for frame window 178\n",
      "The input video clip is classified as class 0 with confidence interval 0.7663354873657227 for frame window 180\n",
      "The input video clip is classified as class 0 with confidence interval 0.6700001955032349 for frame window 182\n",
      "The input video clip is classified as class 0 with confidence interval 0.7869867086410522 for frame window 184\n",
      "The input video clip is classified as class 0 with confidence interval 0.933322548866272 for frame window 186\n",
      "The input video clip is classified as class 0 with confidence interval 0.9795678853988647 for frame window 188\n",
      "The input video clip is classified as class 0 with confidence interval 0.9721802473068237 for frame window 190\n",
      "The input video clip is classified as class 0 with confidence interval 0.9778245091438293 for frame window 192\n",
      "The input video clip is classified as class 0 with confidence interval 0.9502437114715576 for frame window 194\n",
      "The input video clip is classified as class 0 with confidence interval 0.9505085945129395 for frame window 196\n",
      "The input video clip is classified as class 0 with confidence interval 0.9497425556182861 for frame window 198\n",
      "The input video clip is classified as class 0 with confidence interval 0.9285445809364319 for frame window 200\n",
      "The input video clip is classified as class 0 with confidence interval 0.8065702319145203 for frame window 202\n",
      "The input video clip is classified as class 0 with confidence interval 0.9917014241218567 for frame window 204\n",
      "The input video clip is classified as class 0 with confidence interval 0.9455183744430542 for frame window 206\n",
      "The input video clip is classified as class 0 with confidence interval 0.8569876551628113 for frame window 208\n",
      "The input video clip is classified as class 0 with confidence interval 0.939313530921936 for frame window 210\n",
      "The input video clip is classified as class 0 with confidence interval 0.8592603206634521 for frame window 212\n",
      "The input video clip is classified as class 0 with confidence interval 0.8844126462936401 for frame window 214\n",
      "The input video clip is classified as class 0 with confidence interval 0.9470698833465576 for frame window 216\n",
      "The input video clip is classified as class 0 with confidence interval 0.8964211940765381 for frame window 218\n",
      "The input video clip is classified as class 0 with confidence interval 0.8638609647750854 for frame window 220\n",
      "The input video clip is classified as class 0 with confidence interval 0.49894407391548157 for frame window 222\n",
      "The input video clip is classified as class 49 with confidence interval 0.8132793307304382 for frame window 224\n",
      "The input video clip is classified as class 49 with confidence interval 0.9685763120651245 for frame window 226\n",
      "The input video clip is classified as class 0 with confidence interval 0.5805342793464661 for frame window 228\n",
      "The input video clip is classified as class 49 with confidence interval 0.7990677356719971 for frame window 230\n",
      "The input video clip is classified as class 49 with confidence interval 0.5715988278388977 for frame window 232\n",
      "The input video clip is classified as class 0 with confidence interval 0.8323169350624084 for frame window 234\n",
      "The input video clip is classified as class 0 with confidence interval 0.8921138644218445 for frame window 236\n",
      "The input video clip is classified as class 0 with confidence interval 0.5257077813148499 for frame window 238\n",
      "The input video clip is classified as class 0 with confidence interval 0.8481411337852478 for frame window 240\n"
     ]
    }
   ],
   "source": [
    "N = 4\n",
    "\n",
    "url = 'https://github.com/bryanyzhu/tiny-ucf101/raw/master/abseiling_k400.mp4' \n",
    "video_fname = download(url)\n",
    "vr = decord.VideoReader(video_fname)\n",
    "config_file = './i3d_resnet50_v1_kinetics400.yaml'\n",
    "cfg = get_cfg_defaults()\n",
    "cfg.merge_from_file(config_file)\n",
    "model = get_model(cfg)\n",
    "model.eval()\n",
    "for i in range(2 * N, len(vr) - (2 * N), 2): \n",
    "    frame_id_list = range(i - (2*N), i + (2*N) + 1, N)\n",
    "    video_data = vr.get_batch(frame_id_list).asnumpy()\n",
    "    crop_size = 224\n",
    "    short_side_size = 256\n",
    "    transform_fn = video_transforms.Compose([video_transforms.Resize(short_side_size, interpolation='bilinear'),\n",
    "                                            video_transforms.CenterCrop(size=(crop_size, crop_size)),\n",
    "                                            volume_transforms.ClipToTensor(),\n",
    "                                            video_transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "    clip_input = transform_fn(video_data)\n",
    "    with torch.no_grad():\n",
    "        pred = model(torch.unsqueeze(clip_input, dim=0)).numpy()\n",
    "\n",
    "    # Convert raw logits to probabilities using softmax\n",
    "    probs = torch.nn.functional.softmax(torch.tensor(pred), dim=1).numpy()\n",
    "\n",
    "    # Get the top predicted class and calculate confidence interval\n",
    "    top_class = np.argmax(probs)\n",
    "    confidence_interval = np.max(probs) - np.min(probs)\n",
    "\n",
    "    print(f'The input video clip is classified as class {top_class} with confidence interval {confidence_interval} for frame window {i}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### function to measure average confidence given window size 'N' (Variable # frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_window_confidence(N, vr, model, true_class):\n",
    "    sum_confidence = 0\n",
    "    sum_class = 0\n",
    "    for i in range(N, len(vr) - N, (len(vr) - 2*N - 1) // 3):\n",
    "        frame_id_list = range(i-N, i+N+1)\n",
    "        video_data = vr.get_batch(frame_id_list).asnumpy()\n",
    "        crop_size = 224\n",
    "        short_side_size = 256\n",
    "        transform_fn = video_transforms.Compose([video_transforms.Resize(short_side_size, interpolation='bilinear'),\n",
    "                                                video_transforms.CenterCrop(size=(crop_size, crop_size)),\n",
    "                                                volume_transforms.ClipToTensor(),\n",
    "                                                video_transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "        clip_input = transform_fn(video_data)\n",
    "        with torch.no_grad():\n",
    "            pred = model(torch.unsqueeze(clip_input, dim=0)).numpy()\n",
    "        probs = torch.nn.functional.softmax(torch.tensor(pred), dim=1).numpy()\n",
    "        top_class = np.argmax(probs)\n",
    "        confidence_interval = np.max(probs) - np.min(probs)\n",
    "        if top_class == true_class: \n",
    "            sum_class += 1\n",
    "            sum_confidence += confidence_interval\n",
    "        #print(f'Class: {top_class} \\tConfidence: {confidence_interval} \\tWindow:{i}')\n",
    "    #print(f'Average confidence level for window size {N} is {sum_confidence / (len(vr) - 2*N)}')\n",
    "    #print(f'Predicted top class with accuracy {sum_class / (len(vr) - 2*N)}')\n",
    "    return sum_confidence / (len(vr) - 2*N), sum_class / (len(vr) - 2*N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "83\n",
      "164\n",
      "245\n",
      "5 frames has average confidence of 0.01606677218181331 with an accuracy of 0.016260162601626018\n",
      "3\n",
      "84\n",
      "165\n",
      "246\n",
      "7 frames has average confidence of 0.016385315138785564 with an accuracy of 0.01639344262295082\n",
      "4\n",
      "84\n",
      "164\n",
      "244\n",
      "9 frames has average confidence of 0.01638208637552813 with an accuracy of 0.01652892561983471\n",
      "5\n",
      "84\n",
      "163\n",
      "242\n",
      "11 frames has average confidence of 0.016626195112864176 with an accuracy of 0.016666666666666666\n",
      "6\n",
      "85\n",
      "164\n",
      "243\n",
      "13 frames has average confidence of 0.015279303578769459 with an accuracy of 0.01680672268907563\n",
      "7\n",
      "85\n",
      "163\n",
      "241\n",
      "15 frames has average confidence of 0.01670145887439534 with an accuracy of 0.01694915254237288\n",
      "8\n",
      "85\n",
      "162\n",
      "239\n",
      "17 frames has average confidence of 0.016835230792689528 with an accuracy of 0.017094017094017096\n",
      "9\n",
      "86\n",
      "163\n",
      "240\n",
      "19 frames has average confidence of 0.01704691042160166 with an accuracy of 0.017241379310344827\n"
     ]
    }
   ],
   "source": [
    "url = 'https://github.com/bryanyzhu/tiny-ucf101/raw/master/abseiling_k400.mp4' \n",
    "video_fname = download(url)\n",
    "vr = decord.VideoReader(video_fname)\n",
    "config_file = './i3d_resnet50_v1_kinetics400.yaml'\n",
    "cfg = get_cfg_defaults()\n",
    "cfg.merge_from_file(config_file)\n",
    "model = get_model(cfg)\n",
    "model.eval()\n",
    "\n",
    "for i in range(2, 10):\n",
    "    confidence, accuracy = frame_window_confidence(i, vr, model, 0)\n",
    "    print(f'{i*2+1} frames has average confidence of {confidence} with an accuracy of {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our pre-trained model predicts this video clip\n",
    "to be ``abseiling`` action with high confidence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step\n",
    "\n",
    "If you would like to dive deeper into finetuing SOTA video models on your datasets,\n",
    "feel free to read the next `tutorial on finetuning <finetune_custom.html>`__.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
